<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Intelligent and Multimedia Science Laboratory</title>
		<link rel="icon" href="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/logo.png">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="sysuimsl" content="Intelligent and Multimedia Science Laboratory" />
		<!--[if lte IE 8]><script src="../assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../assets/css/main-v20210707.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="../assets/css/ie8.css" /><![endif]-->
		<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
		<script>
		  (adsbygoogle = window.adsbygoogle || []).push({
		    google_ad_client: "ca-pub-6919411062262434",
		    enable_page_level_ads: true
		  });
		</script>
	</head>
	<script src="//instant.page/1.1.0" type="module" integrity="sha384-EwBObn5QAxP8f09iemwAJljc+sU+eUXeL9vSBw1eNmVarwhKk2F9vBEpaN9rsrtp"></script>
	<body class="is-preload">
	    <div id="wrapper">
		<!-- Main -->
			<div id="main">
		    	<div class="inner">
					<!-- Header -->
					<header id="header">
						<table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
                            <tr class="spec">
                                <td width="70%">
									<h11 class="head">Intelligent and Multimedia Science Laboratory</h11>
                                </td>
                                <td width="30%">
								    <ul class="icons">
										<li><a href="https://github.com/sysu-imsl" class="icon fa-github"><span class="label">Github</span></a></li>
										<li><a href="mailto:sysuimsl@126.com" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
										<li><a href="../projects_2Dshape.html">中文版 ☞</a></li>
									</ul>
                                </td>
                            </tr>
                        </table>
					</header>

					<br>
                    <ul class="iconstext">
                        <li><a class="mybuttontop" href="projects_indoor.html">Intelligent Indoor Spatial Sensing</a></li>
                        <li><a class="mybuttontop" href="projects_attack.html">Artificial Intelligence Security</a></li>
                        <li><a class="mybuttonnow">2D/3D Shape and Image Processing</a></li>
                    </ul>
                    <br>

                    <ul class="iconstext">
                        <li><a class="mybuttonlow" href="#sketch">Sketch Generation and Applications</a></li>
                        <li><a class="mybuttonlow" href="#editing_and_synthesis">Image Editing and Synthesis</a></li>
                        <li><a class="mybuttonlow" href="#npr">Non-photorealistic Rendering</a></li>
                        <li><a class="mybuttonlow" href="#fashion">Garment Modeling and Virtual Try-on</a></li>
                        <li><a class="mybuttonlow" href="#3d_modeling">3d Rendering & Modeling</a></li>
                    </ul>

					<section id="sketch">
						<header class="major">
							<h2>Sketch Generation and Applications</h2>
						</header>

                        <table style="margin-bottom: 0px;" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                        <tr class="spec">
                            <td width="39%" valign="top" align="center">
                                <img class="image fit thumb" src="https://cdn.jsdelivr.net/gh/mark-cdn/CDN-for-works@1.5/files/SIG21/gifs/clean/muten-fast.gif" alt="" style="margin-bottom: 0px;" width="100%" border="0">
                            </td>

                            <td width="17%" valign="top" align="center">
                                <img class="image fit thumb"  src="https://cdn.jsdelivr.net/gh/mark-cdn/CDN-for-works@1.4/files/SIG21/gifs/rough/rocket.png" alt="" style="margin-bottom: 0px;" width="100%" border="0">
                                <p class="margin-small">&nbsp;</p>
                                <img src="https://cdn.jsdelivr.net/gh/mark-cdn/CDN-for-works@1.4/files/SIG21/gifs/face/1390_input.png" width="80%">
                            </td>

                            <td width="17%" valign="top" align="center">
                                <img class="image fit thumb"  src="https://cdn.jsdelivr.net/gh/mark-cdn/CDN-for-works@1.4/files/SIG21/gifs/rough/rocket-blue-simplest.gif" alt="" style="margin-bottom: 0px;" width="100%" border="0">
                                <p class="margin-small">&nbsp;</p>
                                <img src="https://cdn.jsdelivr.net/gh/mark-cdn/CDN-for-works@1.4/files/SIG21/gifs/face/face-blue-1390-simplest.gif" width="80%">
                            </td>

                            <td width="27%" valign="top" align="center">
                                <img class="image fit thumb"  src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/color.gif" alt="" style="margin-bottom: 0px;" width="100%" border="0">
                            </td>
                        </tr>
                        </table>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/siggraph2021.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://markmohr.github.io/virtual_sketching/">General Virtual Sketching Framework for Vector Line Art</a></h3>
                                    <p>
                                        Haoran Mo, Edgar Simo-Serra, Chengying Gao<sup>*</sup>, Changqing Zou and Ruomei Wang
                                        <br>
                                        <br>
                                        <strong>Intro: </strong>
                                        Vector line art plays an important role in graphic design, however,
                                        it is tedious to manually create.
                                        We introduce a general framework to produce line drawings from a wide variety of images,
                                        by learning a mapping from raster image space to vector image space.
                                        Our approach is based on a recurrent neural network that draws the lines one by one.
                                        A differentiable rasterization module allows for training with only supervised raster data.
                                        We use a dynamic window around a virtual pen while drawing lines,
                                        implemented with a proposed aligned cropping and differentiable pasting modules.
                                        Furthermore, we develop a stroke regularization loss that encourages the model
                                        to use fewer and longer strokes to simplify the resulting vector image.
                                        Ablation studies and comparisons with existing methods corroborate the efficiency of our approach
                                        which is able to generate visually better results in less computation time,
                                        while generalizing better to a diversity of images and applications.
                                        <br>
                                        <br>
                                        <em>ACM Transactions on Graphics (Proceedings of ACM <strong>SIGGRAPH</strong> 2021) <strong><font color="#FF0000">(*oral)</font></strong> </em>
                                        <br>
                                        <a href="https://esslab.jp/publications/HaoranSIGRAPH2021.pdf">[Paper]</a>
                                        <a href="https://github.com/MarkMoHR/virtual_sketching">[Code]</a>
                                        <a href="https://markmohr.github.io/virtual_sketching/">[Project Page]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/sketchycoco.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://arxiv.org/abs/2003.02683">SketchyCOCO: Image Generation from Freehand Scene Sketches</a></h3>
                                    <p>
                                        Chengying Gao, Qi Liu, Qi Xu, Jianzhuang Liu, Limin Wang, Changqing Zou*
                                        <br>
                                        <br>
                                        <strong>Intro: </strong>
                                        We introduce the first method for automatic image generation from scene-level freehand sketches.
                                        Our model allows for controllable image generation by specifying the synthesis goal
                                        via freehand sketches. The key contribution is an attribute vector bridged
                                        generative adversarial network called edgeGAN which supports high visual-quality image content
                                        generation without using freehand sketches as training data.
                                        We build a large-scale composite dataset called SketchyCOCO to comprehensively
                                        evaluate our solution. We validate our approach on the task of both objectlevel
                                        and scene-level image generation on SketchyCOCO. We demonstrate the method’s capacity
                                        to generate realistic complex scene-level images from a variety of freehand sketches
                                        by quantitative, qualitative results, and ablation studies.
                                        <br>
                                        <br>
                                        <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>) <strong><font color="#FF0000">(*oral)</font></strong> </em>, 2020
                                        <br>
                                        <a href="https://arxiv.org/abs/2003.02683">[Paper]</a>
                                        <a href="https://github.com/sysu-imsl/SketchyCOCO">[Code]</a>
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/mark-cdn/CDN-for-works@1.5/files/SIGA19/colorization2.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://github.com/SketchyScene/SketchySceneColorization">Language-based Colorization of Scene Sketches</a></h3>
                                    <p>
                                        Changqing Zou<sup>#</sup>, Haoran Mo<sup>#</sup>(joint first author), Chengying Gao<sup>*</sup>, Ruofei Du and Hongbo Fu
                                        <br>
                                        <br>
                                        <strong>Intro: </strong>
                                        This paper for the first time presents a language-based system
                                        for interactive colorization of scene sketches, based on semantic comprehension.
                                        The proposed system is built upon deep neural networks
                                        trained on a large-scale repository of scene sketches
                                        and cartoonstyle color images with text descriptions.
                                        Given a scene sketch, our system allows users, via language-based instructions,
                                        to interactively localize and colorize specific foreground object instances
                                        to meet various colorization requirements in a progressive way.
                                        We demonstrate the effectiveness of our approach via comprehensive experimental results
                                        including alternative studies, comparison with the state-of-the-art methods,
                                        and generalization user studies. Given the unique characteristics of language-based inputs,
                                        we envision a combination of our interface with a traditional scribble-based interface
                                        for a practical multimodal colorization system, benefiting various applications.
                                        <br>
                                        <br>
                                        <em>ACM Transactions on Graphics (Proceedings of ACM <strong>SIGGRAPH Asia</strong> 2019) <strong><font color="#FF0000">(*oral)</font></strong> </em>
                                        <br>
                                        <a href="http://mo-haoran.com/files/SIGA19/SketchColorization_paper_SA2019.pdf">[Paper]</a>
                                        <a href="https://github.com/SketchyScene/SketchySceneColorization">[Code]</a>
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/sketchyscene.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://sketchyscene.github.io/SketchyScene/">SketchyScene: Richly-Annotated Scene Sketches</a></h3>
                                    <p>
                                        Changqing Zou<sup>#</sup>, Qian Yu<sup>#</sup>, Ruofei Du, Haoran Mo, Yi-Zhe Song, Tao Xiang, Chengying Gao, Baoquan Chen<sup>*</sup>, and Hao Zhang
                                        <br>
                                        <br>
                                        <strong>Intro: </strong>
                                        This paper constructed the first large-scale dataset of scene sketches called SketchyScene.
                                        We demonstrate the potential impact of SketchyScene by training
                                        new computational models for semantic segmentation of scene sketches.
                                        <br>
                                        <br>
                                        <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2018
                                        <br>
                                        <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Changqing_Zou_SketchyScene_Richly-Annotated_Scene_ECCV_2018_paper.pdf">[Paper]</a>
                                        <a href="https://github.com/SketchyScene/SketchyScene">[Code]</a>
                                    </p>
                                </td>
                            </tr>

                        </table>


					</section>

                    <div align="right">
                        <a href="#">Back to top</a>
                    </div>

                    <section id="editing_and_synthesis">
						<header class="major">
							<h2>Image Editing and Synthesis</h2>
						</header>

                        <p>
                            Including: image inpainting, color restoration and color transfer.
                        </p>
                        <br>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/icme2021inpainting.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://ieeexplore.ieee.org/abstract/document/9428367">Structural Prior Guided Image Inpainting for Complex Scene</a></h3>
                                    <p>
                                        Shuxin Wei, Chengying Gao
                                        <br>
                                        <br>
                                        <strong>Intro: </strong>
                                        Existing deep-learning based image inpainting methods have reach plausible results
                                        for small corrupted regions with rich context information.
                                        However, these methods fail to generate semantically reasonable results and clear boundaries.
                                        In this paper, we disentangle inpainting for complex scene into two stages:
                                        semantic segmentation map inpainting and segmentation guided texture inpainting.
                                        We use feature correspondence matrix to find correlation between segmentation maps
                                        and known region of corrupted images and realize texture generation of corrupted region.
                                        <br>
                                        <br>
                                        <em>International Conference on Multimedia & Expo (<strong>ICME</strong>)</em>, 2021  <strong><font color="#FF0000">(*oral)</font></strong>
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/abstract/document/9428367">[Paper]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/jisuanjixuebao19.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="">基于稀疏结构的复杂物体修复</a></h3>
                                    <p>
                                        高成英，徐仙儿，罗燕媚，王栋
                                        <br>
                                        <br>
                                        <em>计算机学报</em>，2019
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/Neurocomputing18.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://www.sciencedirect.com/science/article/pii/S0925231218306672">An edge-refined vectorized deep colorization model for grayscale-to-color images</a></h3>
                                    <p>
                                        Zhuo Su, Xiangguo Liang, Jiaming Guo, Chengying Gao, Xiaonan Luo
                                        <br>
                                        <br>
                                        <em>Neurocomputing</em>, 2018
                                        <br>
                                        <a href="https://www.sciencedirect.com/science/article/pii/S0925231218306672">[Paper]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/spic17.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://www.sciencedirect.com/science/article/pii/S0923596517300772">Data-Driven Image Completion for Complex Object</a></h3>
                                    <p>
                                        Chengying Gao, Yanmei Luo, Hefeng Wu*, Dong Wang
                                        <br>
                                        <br>
                                        <em>Signal Processing: Image Communication</em>, 2017
                                        <br>
                                        <a href="https://www.sciencedirect.com/science/article/pii/S0923596517300772">[Paper]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/color-transfer.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://changqingzou.weebly.com/uploads/5/9/3/6/59369643/wang_et_al-2017-computer_graphics_forum-min.pdf">L0 Gradient-Preserving Color Transfer</a></h3>
                                    <p>
                                        Dong Wang, Changqing Zou, Guiqing Li, Chengying Gao, Zhuo Su, Ping Tan
                                        <br>
                                        <br>
                                        <em>Computer Graphics Forum (<strong>CGF</strong>)</em>, 2017
                                        <br>
                                        <a href="https://changqingzou.weebly.com/uploads/5/9/3/6/59369643/wang_et_al-2017-computer_graphics_forum-min.pdf">[Paper]</a>
                                    </p>
                                </td>
                            </tr>

                        </table>

					</section>

                    <div align="right">
                        <a href="#">Back to top</a>
                    </div>

                    <section id="npr">
						<header class="major">
							<h2>Non-Photorealistic Rendering</h2>
						</header>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/pencil-art.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%" class="tdp">
								    <h3> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13334">PencilArt: A Chromatic Penciling Style Generation Framework</a></h3>
                                    <p>
                                        Chengying Gao, Mengyue Tang, Xiangguo Liang, Zhou Su, Changqing Zou
                                        <br>
                                        <br>
                                        <em>Computer Graphics Forum (<strong>CGF</strong>)</em>, 2018
                                        <br>
                                        <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13334">[Paper]</a>
                                    </p>
                                </td>
                            </tr>

                        </table>
					</section>

                    <div align="right">
                        <a href="#">Back to top</a>
                    </div>

                    <section id="fashion">
                        <header class="major">
							<h2>Garment Modeling and Virtual Try-on</h2>
						</header>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/fashionGAN.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13552">FashionGAN: Display your fashion design using Conditional Generative Adversarial Nets</a></h3>
                                    <p>	Yirui Cui, Qi Liu, Chengying Gao*, Zhuo Su
                                        <br>
                                        <br>
                                        <em>Computer Graphics Forum (Proceedings of <strong>Pacific Graphics</strong> 2018) <strong><font color="#FF0000">(*oral)</font></strong></em>
                                        <br>
                                        <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13552">[Paper]</a>
                                        <a href="https://github.com/Cuiyirui/FashionGAN">[Code]</a>
										<a href="https://drive.google.com/drive/folders/1DACqCXlJRQxRysO6RVNO7vOoR8YzrjTQ?usp=sharing">[Dataset]</a>
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/pcm18.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-00776-8_25">Automatic 3D Garment Fitting Based on Skeleton Driving</a></h3>
                                    <p> Haozhong Cai, Guangyuan Shi, Chengying Gao*, Dong Wang
                                        <br>
                                        <br>
                                        <em>Pacific-Rim Conference on Multimedia (<strong>PCM</strong>) <strong><font color="#FF0000">(*oral)</font></strong></em>, 2018
                                        <br>
                                        <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-00776-8_25">[Paper]</a>
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/pg14.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://diglib.eg.org/handle/10.2312/pgs.20141250.043-048">Automatic Garment Modeling From Front And Back Images</a></h3>
                                    <p>	Lifeng Huang, Chengying Gao*
                                        <br>
                                        <br>
                                        <em>Pacific Graphics (<strong>PG</strong>)</em>, 2014
                                        <br>
                                        <a href="https://diglib.eg.org/handle/10.2312/pgs.20141250.043-048">[Paper]</a>
                                    </p>
                                </td>
                            </tr>

                        </table>

                    </section>

                    <div align="right">
                        <a href="#">Back to top</a>
                    </div>

					<section id="3d_modeling">
                        <header class="major">
							<h2>3d Rendering & Modeling</h2>
						</header>

                        <p>
                            Including: fast fluid surface reconstruction based on narrow band method, fabric modeling and rendering.
                        </p>
                        <br>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/cgi2020.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%" class="tdp">
								    <h3> <a href="https://link.springer.com/article/10.1007/s00371-020-01898-2">A Completely Parallel Surface Reconstruction Method for Particle-Based Fluids</a></h3>
                                    <p>
										Wencong Yang, Chengying Gao
                                        <br>
                                        <br>
                                        <strong>Intro: </strong>
                                        In this paper, a fast, simple and extremely accurate narrow-band method of
										fluid surface is proposed firstly, which makes the surface reconstruction algorithm
										(such as marching cube) accurately process the valid fluid surface area,
										which greatly avoids the useless calculation process. At the same time,
										we analyze the potential race conditions and conditional branching in the reconstruction process,
										by using mutual exclusive prefix sum algorithm,
										the whole process of fluid surface reconstruction is completely parallelized,
										which greatly speeds up the efficiency of surface reconstruction.
                                        <br>
                                        <br>
                                        <em>Computer Graphics International (<strong>CGI</strong>) </em>, 2020
                                        <br>
                                        <a href="https://link.springer.com/article/10.1007/s00371-020-01898-2">[Paper]</a>
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/fabric-model.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%" class="tdp">
								    <h3> <a href="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/docs/fabric-model.pdf">Fully automatic algorithm on yarn model generation</a></h3>
                                    <p>
										Zekun Zhang
                                        <br>
                                        <br>
                                        <a href="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/docs/fabric-model.pdf">[Introduction (PPT)]</a>
                                    </p>
                                </td>
                            </tr>
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/projects/fabric-render.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%" class="tdp">
								    <h3> <a href="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/docs/fabric-render.pdf">Microscopic model based real time algorithm on fabric rendering</a></h3>
                                    <p>
										Xingrong Luo
                                        <br>
                                        <br>
                                        <a href="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/docs/fabric-render.pdf">[Introduction (PPT)]</a>
                                    </p>
                                </td>
                            </tr>


                        </table>


                    </section>
                    
                    <div align="right">
                        <a href="#">Back to top</a>
                        <br>
                        <p> &nbsp; </p>
                    </div>

				</div>
			</div>
			
			<!-- Sidebar -->
				<div id="sidebar">
					<div class="inner">

						<!-- Search -->
							<section id="search" class="alt">
								<!--<form method="post" action="#">-->
									<!--<input type="text" name="query" id="query" placeholder="Search" />-->
								<!--</form>-->
                                <div style="text-align:center" >
                                    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/files/images/logo2.png" alt="" width="100%"/>
                                </div>
							</section>

						<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">Home</a></li>
									<li><a href="projects_2Dshape.html">Projects</a></li>
									<li><a href="publications.html">Publications</a></li>
									<li><a href="members.html">Members</a></li>
									<li><a href="students.html">Student Development</a></li>
									<li><a href="materials_datasets.html">Related Materials</a></li>
									<!--
									<li>
										<span class="opener">Submenu</span>
										<ul>
											<li><a href="#">Lorem Dolor</a></li>
											<li><a href="#">Ipsum Adipiscing</a></li>
											<li><a href="#">Tempus Magna</a></li>
											<li><a href="#">Feugiat Veroeros</a></li>
										</ul>
									</li>
									<li><a href="#">Etiam Dolore</a></li>
									<li><a href="#">Adipiscing</a></li>
									<li>
										<span class="opener">Another Submenu</span>
										<ul>
											<li><a href="#">Lorem Dolor</a></li>
											<li><a href="#">Ipsum Adipiscing</a></li>
											<li><a href="#">Tempus Magna</a></li>
											<li><a href="#">Feugiat Veroeros</a></li>
										</ul>
									</li>
									-->
								</ul>
							</nav>

						<!-- Section -->
						<!--
							<section>
								<header class="major">
									<h2>Ante interdum</h2>
								</header>
								<div class="mini-posts">
									<article>
										<a href="#" class="image"><img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/images/pic07.jpg" alt="" /></a>
										<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
									</article>
									<article>
										<a href="#" class="image"><img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/images/pic08.jpg" alt="" /></a>
										<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
									</article>
									<article>
										<a href="#" class="image"><img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.30/images/pic09.jpg" alt="" /></a>
										<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
									</article>
								</div>
								<ul class="actions">
									<li><a href="#" class="button">More</a></li>
								</ul>
							</section>
                        -->
						<!-- Section -->
							<section>
								<header class="major">
									<h2>Get in touch</h2>
								</header>
								<ul class="contact">
									<li class="fa-envelope-o">Email: <a href="#">sysuimsl@126.com</a></li>
									<li class="fa-home">Address: <a href="https://goo.gl/maps/P7iu1XtZfrk5TsKz5">Room A207, School Of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China</a>
									</li>
								</ul>
								<!--<article class="5u 10u$(xsmall) work-item">-->
										<!--<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&d=mhnrYabZI2bz_eHk1W_A8VvNxtAjYBrWfIfxbLnTRPQ&co=4c5459&cmo=faa659'></script>-->
								<!--</article>-->
								<!--<a href="https://info.flagcounter.com/Dsap"><img src="https://s11.flagcounter.com/count2/Dsap/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>-->
							</section>

						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">
									<li>Copyright &copy; 2019-2021 SYSU-IMSL</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</footer>

					</div>
				</div>
        <!-- push the page to Baidu -->
		<script>
		(function(){
		    var bp = document.createElement('script');
		    var curProtocol = window.location.protocol.split(':')[0];
		    if (curProtocol === 'https'){
		   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
		  }
		  else{
		  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
		  }
		    var s = document.getElementsByTagName("script")[0];
		    s.parentNode.insertBefore(bp, s);
		})();
		</script>
		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>
	</body>
</html>
