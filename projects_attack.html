<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>智能与多媒体科学实验室</title>
		<link rel="icon" href="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/logo.png">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="sysuimsl" content="智能与多媒体科学实验室" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main-v20210707.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
		<script>
		  (adsbygoogle = window.adsbygoogle || []).push({
		    google_ad_client: "ca-pub-6919411062262434",
		    enable_page_level_ads: true
		  });
		</script>
	</head>
	<script src="//instant.page/1.1.0" type="module" integrity="sha384-EwBObn5QAxP8f09iemwAJljc+sU+eUXeL9vSBw1eNmVarwhKk2F9vBEpaN9rsrtp"></script>
	<body class="is-preload">
	    <div id="wrapper">
		<!-- Main -->
			<div id="main">
		    	<div class="inner">
					<!-- Header -->
					<header id="header">
						<table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
                            <tr class="spec">
                                <td width="70%">
									<h11 class="head-zh">智能与多媒体科学实验室</h11>
                                </td>
                                <td width="30%">
								    <ul class="icons">
										<li><a href="https://github.com/sysu-imsl" class="icon fa-github"><span class="label">Github</span></a></li>
										<li><a href="mailto:sysuimsl@126.com" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
										<li><a href="en/projects_attack.html">Eng. Version ☞</a></li>
									</ul>
                                </td>
                            </tr>
                        </table>
					</header>

                    <br>


                    <!--<h2>-->
                        <!--<ul class="icons">-->
							<!--<li><a href="projects_indoor_en.html">test</a></li>-->
							<!--<li><a href="projects_indoor_en.html">test1</a></li>-->
                            <!--<li><a href="projects_indoor_en.html">test3</a></li>-->
                        <!--</ul>-->
                    <!--</h2>-->

                    <ul class="iconstext">
                        <li><a class="mybuttontop" href="projects_indoor.html">室内空间位置智能感知与应用</a></li>
                        <li><a class="mybuttonnow">面向计算机视觉的人工智能安全分析</a></li>
                        <li><a class="mybuttontop" href="projects_2Dshape.html">二维/三维图形图像生成、理解与应用</a></li>
                    </ul>
                    <br>

                    <ul class="iconstext">
                        <li><a class="mybuttonlow" href="#attack">对抗攻防学习</a></li>
                        <li><a class="mybuttonlow" href="#video">人群计数</a></li>
                    </ul>
					
				<!-- Two -->

                    <section id="attack">
                        <header class="major">
							<h2 class="head-zh">对抗攻防学习</h2>
						</header>

                        <p> 深度神经网络目前已经获得了突破式发展，并且在多个领域得到了广泛应用。
                            然而，深度神经网络同样面临着被攻击的威胁，也就是“对抗样本”：
                            攻击者通过在源数据上增加难以通过感官辨识到的细微改变，让神经网络模型做出错误的分类决定。
                            <br>
                            本团队通过研究对抗样本的生成原理和算法实现，有助于分析基于深度学习的系统存在的安全漏洞，
                            并针对此类攻击建立更好的防范机制，加速机器学习领域的进步。
                            相关链接：
                            <br>
                            1. FaceBook AI：<a href="https://ai.facebook.com/results/?q=adversarial">对抗攻防学习研究</a>、
                            <a href="https://ai.facebook.com/results/?q=robustness">鲁棒性分析</a>
                            <br>
                            2. 对抗攻防学习综艺节目：<a href="https://www.iqiyi.com/v_ll6u9ojc4s.html?vfm=2008_aldbd&fv=p_02_01">《燃烧吧！天才程序员》</a>


                        </p>
                        <br>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
							<tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/attack-pr2022.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://www.sciencedirect.com/science/article/pii/S0031320322003120?dgcid=coauthor">Cyclical Adversarial Attack Pierces Black-box Deep Neural Networks</a></h3>
                                    <p>
										Lifeng Huang, Shuxin Wei, Chengying Gao, Ning Liu
										<br>
                                        <br>
                                        <strong>简介：</strong>
                                        深度神经网络 (DNN) 已显示出抵抗对抗性攻击的脆弱性。通过利用对抗样本的可迁移性，
                                        攻击者可以在不访问底层黑盒模型信息的情况下欺骗人工智能系统。然而，大部分对抗样本迁移到防御模型时往往表现不佳，
                                        这可能会给人一种虚假的安全感。在本文中，我们提出了循环对抗攻击（CA2），这是一种通用且直接的方法，
                                        可提高可转移性以攻破防御模型。我们首先从优化的角度重新审视基于动量的方法，发现它们通常存在可迁移性饱和困境。
                                        为了解决这个问题，CA2执行循环优化算法来生成对抗样本。与累积速度以不断更新解决方案的标准动量策略不同，
                                        我们将生成过程分为多个阶段，并将前一阶段的速度向量视为适当的知识，以指导更大步长的新对抗性攻击。
                                        此外，CA2在每次优化时以循环方式应用一种新颖且兼容的增强算法，以进一步增强黑盒可迁移性，称为循环增强。
                                        在各种模型上进行的大量实验不仅验证了每个设计算法在 CA2中的有效性，而且还说明了我们的方法与现有迁移对抗攻击相比的优越性。
                                        <br>
                                        <br>
                                        <em>Pattern Recognition (<strong>PR</strong>)</em>, 2022
                                        <br>
                                        <a href="https://www.sciencedirect.com/science/article/pii/S0031320322003120?dgcid=coauthor">[论文]</a>
                                        <a href="https://github.com/mesunhlf/CA2">[代码]</a>
                                    </p>
                                </td>
                            </tr>

							<tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/icme2021attack.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://github.com/zhuangwz/ICME2021_self_augmentation">Enhancing Adversarial Examples Via Self-Augmentation</a></h3>
                                    <p>
										Lifeng Huang, Wenzi Zhuang, Chengying Gao, Ning Liu
										<br>
                                        <br>
                                        <strong>简介：</strong>
                                        最近，对抗性攻击对深度神经网络的安全性提出了挑战，这促使研究人员建立各种防御方法。
										然而，目前的防御措施是否足以实现真正的安全？
										为了回答这个问题，我们提出了一种自我增强方法（SA）来规避防御者到可迁移的对抗样本。
										具体而言，自增强包括两种策略：
										（1）自身集成，将额外的卷积层应用于现有深度神经网络以构建各种虚拟模型，
										再将这些虚拟模型的输出层融合在一起以实现集成模型效果并防止过度拟合；
										（2）偏差增强，它基于对防御模型的观察，即输入数据被高度弯曲的损失面包围，
										从而启发我们将偏差向量添加于输入数据，使其逃离局部的空间。
										值得注意的是，我们可以自然地将自我增强与现有的迁移攻击方法相结合，
										以建立更多更强的可迁移的对抗性攻击。
										我们对四种普通模型和十种防御方法进行了大量实验，
										结果表明与最先进的可迁移攻击相比我们的方法具有较大优越性。
                                        <br>
                                        <br>
                                        <em>International Conference on Multimedia & Expo (<strong>ICME</strong>)</em>, 2021  <strong><font color="#FF0000">(*oral)</font></strong>
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/abstract/document/9428372">[论文]</a>
                                        <a href="https://github.com/zhuangwz/ICME2021_self_augmentation">[代码]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/ruanjianxuebao.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="">一种基于进化策略和注意力机制的黑盒对抗攻击算法</a></h3>
                                    <p>
										黄立峰，庄文梓，廖泳贤，刘宁
										<br>
                                        <br>
                                        <strong>简介：</strong>
                                        深度神经网络在许多计算机视觉任务中都取得了优异的结果，并在不同领域中得到广泛应用。
										然而研究发现，在面对对抗样本攻击时，深度神经网络表现得较为脆弱，严重威胁着各类系统的安全性。
										在现有的对抗样本攻击中，由于黑盒攻击具有模型不可知性质和查询限制等约束，更接近实际的攻击场景，
										但现有的黑盒攻击方法存在攻击效率较低与隐蔽性弱的缺陷。因此，本文提出了一种基于进化策略的黑盒对抗攻击方法，
										充分考虑了攻击过程中梯度更新方向的分布关系，自适应学习较优的搜索路径，提升攻击的效率。
										在成功攻击的基础上，结合注意力机制，基于类间激活热力图将扰动向量分组和压缩优化，
										减少在黑盒攻击过程中积累的冗余扰动，增强优化后的对抗样本的不可感知性。
										通过与其他四种最新的黑盒对抗攻击方法(AutoZOOM,QL-Attack,FD-Attak,D-based Attack)
										在七种深度神经网络上进行对比，验证了本文提出方法的有效性与鲁棒性。
                                        <br>
                                        <br>
                                        <em>软件学报</em>, 2020
                                        <br>
                                    </p>
                                </td>
                            </tr>

							<tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/attack-cvpr2020.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://arxiv.org/pdf/1909.04326">Universal Physical Camouflage Attacks on Object Detectors</a></h3>
                                    <p>
										Lifeng Huang, Chengying Gao, Yuyin Zhou, Changqing Zou, Cihang Xie, Alan Yuille, Ning Liu
										<br>
                                        <br>
                                        <strong>简介：</strong>
                                        论文提出了一种物理场景下对抗攻击检测模型的方法。现有的方法通常只能生成个体级别的伪装图案，
										且约束物体需具备刚体或平面的特征（如路牌、车等），难以在实际中应用。针对这些缺陷，
										该工作提出了一种通用级别的伪装攻击框架，可以对一类中所有实例物体进行有效的攻击，
										且在非刚体与非平面的攻击场景下保持了较高的鲁棒性。该方法的主要思路包括两部分：<br>
										(1)数据生成阶段，即通过同时对复杂对象的内在性质（如形变、遮挡等）与外在环境（如光照、角度等）
										进行物理仿真，生成拟真数据集；<br>
										(2)联合攻击阶段，即基于生成的数据集对RPN网络和分类网络同时展开攻击，
										结合语义约束降低攻击目标的置信度。两个阶段以迭代优化的方式生成伪装图案。
										此外，针对该领域缺少评估环境的困境，该工作构建了一个参数可控的合成数据库（AttackScenes）。
										通过大量的实验证明，该工作提出的方法不仅能在虚拟场景和现实世界中对目标检测模型进行有效的攻击，
										还展现出较好的泛化性与迁移性。
                                        <br>
                                        <br>
                                        <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
                                        <br>
                                        <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Universal_Physical_Camouflage_Attacks_on_Object_Detectors_CVPR_2020_paper.pdf">[论文]</a>
                                        <a href="https://mesunhlf.github.io/index_physical.html">[项目主页]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/attack-guap.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="http://www.acml-conf.org/2019/conference/accepted-papers/419/?from=singlemessage&isappinstalled=0&scene=1&clicktime=1577243300&enterid=1577243300">G-UAP: Generic Universal Adversarial Perturbation that Fools RPN-based Detectors</a></h3>
                                    <p>
										Xing wu, Lifeng Huang, Chengying Gao*
										<br>
                                        <br>
                                        <strong>简介：</strong>
                                        Our paper proposed the G-UAP which is the first work to craft universal
                                        adversarial perturbations to fool the RPN-based detectors. G-UAP focuses
                                        on misleading the foreground prediction of RPN to background to make detectors
                                        detect nothing.
                                        <br>
                                        <br>
                                        <em>Asian Conference on Machine Learning (<strong>ACML</strong>)</em>, 2019
										<br>
                                        <a href="http://www.acml-conf.org/2019/conference/accepted-papers/419/?from=singlemessage&isappinstalled=0&scene=1&clicktime=1577243300&enterid=1577243300">[论文]</a>
                                    </p>
                                </td>
                            </tr>

                        </table>

                    </section>
                    <div align="right">
                        <a href="#">Back to top</a>
                    </div>

                    <section id="video">
                        <header class="major">
							<h2 class="head-zh">人群计数</h2>
						</header>

						<p> 行人检测与属性分析通过视频分析，实现对监控区域中的人群人数分布、人群外观属性、行人运动轨迹进行精确分析，
                            该研究在安防监控、自动驾驶及线下商业领域具有重要的意义。
                            <br>
                            相关链接：
                            <br>
                            1. 香港城市大学 人群计数研究：<a href="http://visal.cs.cityu.edu.hk/research/aaai20-3d-counting/">资料1</a>、
                            <a href="http://visal.cs.cityu.edu.hk/research/cvpr2019wacc/">资料2</a>

                        </p>
                        <br>

                        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/acmmm2020.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413698">Scale-aware Progressive Optimization Network</a></h3>
                                    <p>
                                        Ying Chen, Lifeng Huang, Chengying Gao, Ning Liu
                                        <br>
                                        <br>
                                        <strong>简介：</strong>
                                        人群计数由于广阔的应用前景而引起了越来越多地关注。
                                        该领域最大的挑战之一是人群尺度的巨大变化，其严重影响了密度估计的准确性。
                                        为此，本文提出了一种用于人群计数的尺度感知渐进优化网络（SPO-Net），
                                        该网络可以克服高度拥挤场景中的尺度变化问题以实现高质量的密度图估计。
                                        具体而言，SPO-Net的第一阶段（BPS）主要集中于对输入图像进行预处理，
                                        并从分离的多层特征中融合高级语义信息和低级空间信息。
                                        SPO-Net的第二阶段（RGS），旨在从多尺度特征和循环训练方式中学习一个尺度适应的网络。
                                        此外，为了更好地学习多尺寸区域的局部相关性并减少冗余计算，网络在每次循环中引入了具有类比目标的不同监督，
                                        称为渐进优化策略。
                                        本文在三个具有挑战性的人群计数数据集上进行的广泛实验不仅证明了SPO-Net中每个部分的有效性，
                                        而且证明了本文提出的方法与以往方法相比的优越性。
                                        <br>
                                        <br>
                                        <em>ACM MultiMedia (<strong>ACM MM</strong>)</em>, 2020
                                        <br>
                                        <a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413698">[论文]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/icme2020-fisheye.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://ieeexplore.ieee.org/abstract/document/9102923">Self-Bootstrapping Pedestrian Detection in Downward-Viewing Fisheye Cameras Using Pseudo-Labeling</a></h3>
                                    <p>
                                        Kaishi Gao, Qun Niu, Haoquan You, Chengying Gao
                                        <br>
                                        <br>
                                        <strong>简介：</strong>
                                        垂直鱼眼摄像头由于其大视角、避免了遮挡等优点被广泛应用于视频监控领域。
                                        然而由于缺乏具有实例标注的行人数据集，基于垂直鱼眼视频的行人分析研究受到严重制约。
                                        针对于此，本文创新地提出一种基于区域分割的垂直鱼眼行人自动标注方法，可实现具有实例标注的垂直鱼眼行人数据集的自动构造。
                                        本文首先根据入射光线与摄像头的光轴形成的夹角将垂直鱼眼镜头的监控区域分为斜照和垂直两个区域，然后分别对两个区域中行人进行标注：
                                        在斜照区域，利用斜照区域行人与现有数据集中行人存在一定相似程度的特点，使用微调后的全监督行人检测网络对该区域行人进行标注；
                                        在垂直区域，通过利用监控视频中行人存在时间和空间连贯性的特点，使用视觉跟踪算法，结合斜照区域的行人检测的结果，对该区域行人进行标注。
                                        本文方法生成具有实例标注的垂直鱼眼行人数据集可直接用于训练垂直鱼眼行人检测网络，也为其它垂直鱼眼视频分析领域提供数据支持。
                                        <br>
                                        <br>
                                        <em>International Conference on Multimedia & Expo (<strong>ICME</strong>)</em>, 2020
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/abstract/document/9102923/">[论文]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/icme2020-crowd.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://ieeexplore.ieee.org/abstract/document/9102854">Scale-Aware Rolling Fusion Network for Crowd Counting</a></h3>
                                    <p>
                                        Ying Chen, Chengying Gao, Zhuo Su, Xiangjian He, Ning Liu
                                        <br>
                                        <br>
                                        <strong>简介：</strong>
                                        在人群计数的任务中，存在遮挡，背景干扰和人群大尺度变化等因素，影响人群计数的精度，其中人群尺度的变化对计数的影响最大。
                                        本文提出了一个两阶段的尺度感知循环融合网络用于解决人群计数中存在的挑战。
                                        首先第一阶段使用一个有非对称的编码-解码结构，在尽可能保留图片中提取的信息的同时排除了部分干扰信息。
                                        其次第二阶段的循环监督网络，不同于以往通过多列或多分支的结构，使用循环结构逐步提取多尺度特征并在循环中使用监督渐进优化提取的特征。
                                        与以往的方法相比，循环监督网络的优势是不需要通过增加参数却能够通过循环极大地丰富感受野，从而更好地解决人群尺度变化的问题。
                                        本文的方法在三个广泛使用的公开的人群计数数据集上进行了测试并取得了最优的结果。
                                        <br>
                                        <br>
                                        <em>International Conference on Multimedia & Expo (<strong>ICME</strong>)</em>, 2020
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/abstract/document/9102854/">[论文]</a>
                                    </p>
                                </td>
                            </tr>


                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/ADCrowdNet.png" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_ADCrowdNet_An_Attention-Injective_Deformable_Convolutional_Network_for_Crowd_Understanding_CVPR_2019_paper.pdf">ADCrowdNet: An Attention-Injective Deformable Convolutional Network for Crowd Understanding</a></h3>
                                    <p>
                                        Ning Liu, Yongchao Long, Changqing Zou, Qun Niu, Li Pan, and Hefeng Wu
                                        <br>
                                        <br>
                                        <strong>简介：</strong>
                                        人群计数中背景干扰和尺度变化会对密度回归的准确度造成巨大的影响，
                                        本研究通过设计一个注意力图生成器，将网络注意力集中在人群从而大大减少背景干扰。
                                        同时，利用可变形卷积设计了一个多尺度特征提取的网络。
                                        最终将两者结合预测高质量的密度图实现更精确的人群计数。
                                        <br>
                                        <br>
                                        <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2019
                                        <br>
                                        <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_ADCrowdNet_An_Attention-Injective_Deformable_Convolutional_Network_for_Crowd_Understanding_CVPR_2019_paper.pdf">[论文]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/video-spic18.jpg" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://www.sciencedirect.com/science/article/pii/S092359651730262X">Weak-structure-aware visual object tracking with bottom-up and top-down context exploration</a></h3>
                                    <p>
                                        Liu Ning, Liu Chang, Wu Hefeng*, and Zhu Hengzheng
                                        <br>
                                        <br>
                                        <strong>简介：</strong>
                                        由于运动、形状变形、遮挡和周围环境的影响，物体的外观会发生很大的变化，影响物体检测和跟踪的结果。
                                        研究提出了一种利用目标及其周围环境的弱结构对目标进行建模和定位的方法，
                                        并通过与现有方法的对比验证了所提出方法的优越性。
                                        <br>
                                        <br>
                                        <em>Signal Processing: Image Communication (<strong>SPIC</strong>)</em>, 2018
                                        <br>
                                        <a href="https://www.sciencedirect.com/science/article/pii/S092359651730262X">[论文]</a>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="30%">
								    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/projects/vedio-toc15.gif" alt="" width="100%" border="1"/>
                                </td>
                                <td width="70%">
								    <h3> <a href="https://ieeexplore.ieee.org/document/6819051/">Hierarchical Ensemble of Background Models for PTZ-based Video Surveillance</a></h3>
                                    <p>
                                        <strong>简介：</strong>
                                        研究了一种适用于PTZ摄像机的视频监控分层背景模型，在此基础上实现了由背景建模、
                                        观测帧配准和目标跟踪三个关键部分构成的跟踪系统，并且在多个具有挑战性的场景中取得了优异的跟踪效果。
                                        <br>
                                        <br>
                                        <em>IEEE Transactions on Cybernetics (<strong>TCYB</strong>)</em>, 2015
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/document/6819051/">[论文]</a>
                                    </p>
                                </td>
                            </tr>

                        </table>
                    </section>

					<div align="right">
                        <a href="#">Back to top</a>
                        <br>
                        <p> &nbsp; </p>
                    </div>

				</div>
			</div>
			
			<!-- Sidebar -->
				<div id="sidebar">
					<div class="inner">

						<!-- Search -->
							<section id="search" class="alt">
								<!--<form method="post" action="#">-->
									<!--<input type="text" name="query" id="query" placeholder="Search" />-->
								<!--</form>-->
                                <div style="text-align:center" >
                                    <img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/files/images/logo2.png" alt="" width="100%"/>
                                </div>
							</section>

						<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a class="menu-zh" href="index.html">主页</a></li>
									<li><a class="menu-zh" href="projects_indoor.html">研究项目</a></li>
									<li><a class="menu-zh" href="publications_papers.html">论文发表</a></li>
									<li><a class="menu-zh" href="members.html">成员信息</a></li>
									<li><a class="menu-zh" href="students_dev.html">学生发展</a></li>
									<li><a class="menu-zh" href="materials_datasets.html">相关资料</a></li>
									<!--
									<li>
										<span class="opener">Submenu</span>
										<ul>
											<li><a href="#">Lorem Dolor</a></li>
											<li><a href="#">Ipsum Adipiscing</a></li>
											<li><a href="#">Tempus Magna</a></li>
											<li><a href="#">Feugiat Veroeros</a></li>
										</ul>
									</li>
									<li><a href="#">Etiam Dolore</a></li>
									<li><a href="#">Adipiscing</a></li>
									<li>
										<span class="opener">Another Submenu</span>
										<ul>
											<li><a href="#">Lorem Dolor</a></li>
											<li><a href="#">Ipsum Adipiscing</a></li>
											<li><a href="#">Tempus Magna</a></li>
											<li><a href="#">Feugiat Veroeros</a></li>
										</ul>
									</li>
									-->
								</ul>
							</nav>

						<!-- Section -->
						<!--
							<section>
								<header class="major">
									<h2>Ante interdum</h2>
								</header>
								<div class="mini-posts">
									<article>
										<a href="#" class="image"><img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/images/pic07.jpg" alt="" /></a>
										<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
									</article>
									<article>
										<a href="#" class="image"><img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/images/pic08.jpg" alt="" /></a>
										<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
									</article>
									<article>
										<a href="#" class="image"><img src="https://cdn.jsdelivr.net/gh/sysu-imsl/CDN-for-IMSL@1.42/images/pic09.jpg" alt="" /></a>
										<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
									</article>
								</div>
								<ul class="actions">
									<li><a href="#" class="button">More</a></li>
								</ul>
							</section>
                        -->
						<!-- Section -->
							<section>
								<header class="major">
									<h2 class="head-zh">联系方式</h2>
								</header>
								<ul class="contact">
									<li class="fa-envelope-o">联系邮箱: <a href="#">sysuimsl@126.com</a></li>
									<li class="fa-home">地址: <a href="https://goo.gl/maps/P7iu1XtZfrk5TsKz5">中国 广州, 中山大学, 计算机学院, A409室</a>
									</li>
								</ul>
								<!--<article class="5u 10u$(xsmall) work-item">-->
										<!--<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&d=mhnrYabZI2bz_eHk1W_A8VvNxtAjYBrWfIfxbLnTRPQ&co=4c5459&cmo=faa659'></script>-->
								<!--</article>-->
								<!--<a href="https://info.flagcounter.com/Dsap"><img src="https://s11.flagcounter.com/count2/Dsap/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>-->
							</section>

						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">
									<li>Copyright &copy; 2019-2022 SYSU-IMSL</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</footer>

					</div>
				</div>
        <!-- push the page to Baidu -->
		<script>
		(function(){
		    var bp = document.createElement('script');
		    var curProtocol = window.location.protocol.split(':')[0];
		    if (curProtocol === 'https'){
		   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
		  }
		  else{
		  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
		  }
		    var s = document.getElementsByTagName("script")[0];
		    s.parentNode.insertBefore(bp, s);
		})();
		</script>
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
	</body>
</html>
